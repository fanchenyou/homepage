<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0023)http://michaelryoo.com/ -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!-- 
<script type="text/javascript" src="hits.php"></script>
 -->


	<title>Chenyou Fan</title>
	<style type="text/css">
	a {
		text-decoration:none;
	}
	a:link {
		color: #045FB4;
	}
	a:visited {
		color: #045FB4;
	}
	body {
		font-family:Arial;
		font-size: 15px;
	}
	li {
		padding: 5px;
	}
	</style>
</head>

<body bgcolor="white">


<table style="width: 1024px;" border="0" cellpadding="15" cellspacing="0"> 

<tbody><tr><td>


<table border="0" cellpadding="3" align="top">
	<tbody><tr>
		<td>
			<img src="./chenyou.jpg">
		</td>
		<td>
			<span style="font-size: 20px;"><b>Chenyou Fan</b></span><br>
			<span style="font-size: 17px;"><b>Ph.D.</b><br>
			<br>
			<span style="font-size: 16px;">Google<br>
			
<!-- 
			<span style="font-size: 16px;">Department of Computer Science and Informatics<br>
			<span style="font-size: 16px;">School of Informatics and Computing<br>
 -->
<!-- 
			<span style="font-size: 16px;">Indiana University Bloomington<br>
 -->


<br>

			<span style="font-size: 16px;"><b>Contact</b><br>
<!-- 			<a href="mailto:fan6@iu.edu">fan6-at-iu.edu</a> -->
			fanchenyou-at-gmail.com
		</span></span></span></span></span></span></span></td>
	</tr>
</tbody></table><br>

<!-- I am now a computer vision engineer at AI&BD team of JD.com USA. <br> -->
I obtained my Ph.D. degree of Computer Science from School of Informatics and Computing, <a href="http://www.iub.edu/" target="_blank">Indiana University</a>. <br>
<!-- My research interests include but not limit to Computer Vision, Machine Learning, Natural Language Processing and Robotics.  <br> -->
<!-- My research topics include predicting robotics motion, recognizing first-person videos, and captioning first-person images with deep learning methods. <br> -->
My research topics include first-person videos, image captioning, video question answering and time series analysis.
<br><br>
<!-- 
<hr style="width: 100%; height: 2px;">



<b><span style="font-size: 18px; color: red;">Recent News</span></b> <br>

<table>

<tbody><tr><td class="newsdate" valign="top"><span class="newsdate"><b>2017/03:</b></span> </td><td> New research on deep robot learning:
<a href="https://arxiv.org/abs/1703.01040" target="_blank">Learning Robot Activities from First-Person Human Videos Using Convolutional Future Regression</a>.<br>
Its example videos can be viewed at <a href="https://youtu.be/OCnp_eduA6Q" target="_blank">[example_robot_demo_video]</a>.


</td></tr><tr><td class="newsdate" valign="top"><span class="newsdate"><b>2017/03:</b></span> </td><td> One paper to appear at ICRA 2017, and one paper to appear at CVPR 2017. The paper details will become available soon.

</td></tr><tr><td class="newsdate" valign="top"><span class="newsdate"><b>2017/02:</b></span> </td><td> Presented a paper on <a href="http://arxiv.org/abs/1604.03196" target="_blank">Privacy-Preserving Human Activity Recognition from Extreme Low Resolution</a> at AAAI 2017.<br>

</td></tr><tr><td class="newsdate" valign="top"><span class="newsdate"><b>2017/02:</b></span> </td><td> Presented a paper on <a href="http://arxiv.org/abs/1605.08140" target="_blank">Learning Latent Sub-events in Activity Videos Using Temporal Attention Filters</a> at AAAI 2017.<br>

</td></tr><tr><td class="newsdate" valign="top"><span class="newsdate"><b>2016/05:</b></span> </td><td> Won the <b><a href="http://www.ieee-ras.org/awards-recognition/conference-awards/69-awards-recognition/society-awards/76-icra-best-vision-paper-sponsored-by-ben-wegbreit" target="_blank">Best Vision Paper Award</a></b> from ICRA 2016.

</td></tr><tr><td class="newsdate" valign="top"><span class="newsdate"><b>2016/06:</b></span> </td><td> Organized the 4th workshop on <a href="http://www.cbi.gatech.edu/fpv2016/" target="_blank">Egocentric (First-Person) Vision</a> at CVPR 2016 with Kris Kitani, Yong Jae Lee, and Yin Li.

</td></tr><tr><td class="newsdate" valign="top"><span class="newsdate"><b>2015/03:</b></span> </td><td>My <a href="http://michaelryoo.com/papers/hri2015_ryoo.pdf" target="_blank">robot-centric activity prediction paper</a> was one of the two nominees for the <b><a href="http://humanrobotinteraction.org/2015/" target="_blank">Best Enabling Technology Award</a></b> at HRI 2015.

</td></tr></tbody></table>
 -->


<hr style="width: 100%; height: 2px;">
<!-- <h3>Curriculum Vitae</h2> <a href="./docs/cv_2019.pdf" target="_blank">pdf</a></h2> -->
<h3>Google Scholar <a href="https://scholar.google.com/citations?user=FRu9MHcAAAAJ&hl=en" target="_blank">here</a></h2>

<!-- 
<hr style="width: 100%; height: 2px;">
<h2>Committee Members</h2>
<a href="https://www.cs.indiana.edu/~djcran/" target="_blank">David J. Crandall</a> <br>
<a href="http://michaelryoo.com/" target="_blank">Michael S. Ryoo</a> <br>
<a href="https://www.cs.indiana.edu/~pwp/" target="_blank">Paul W. Purdom</a> <br>
<a href="http://pages.iu.edu/~huang48/" target="_blank">Chunfeng Huang</a> <br>
 -->

<hr style="width: 100%; height: 2px;">
<h2>Publications <span style="font-size: 18px;">
<!-- [<a href="http://michaelryoo.com/publications_topic.html">by topic</a>] [<a href="http://michaelryoo.com/publications.html">by type</a>] [<a href="http://michaelryoo.com/publications_year.html">by year</a>]-->
</span></h2> 

<!-- <span style="font-size: 13px; font-family: lucida grande, verdana, sans-serif;"> -->
<!-- <h3>List of selected recent publications</h3> -->

<ul>

<li></font> Tianyi Lin, <b>Chenyou Fan</b>, Mengdi Wang, M.I.Jordan. "Improved Sample Complexity for Stochastic Compositional Variance Reduced Gradient." 
American Control Conference 2020 (ACC'20)
<a href="https://arxiv.org/abs/1806.00458" target="_blank">[pdf]</a>
</li>

<li></font> <b>Chenyou Fan</b>, Heng Huang. "Heterogeneous Memory Enhanced Multimodal Attention Model for Video Question Answering." 
IEEE Conference on Computer Vision and Pattern Recognition 2019 (CVPR'19, 25.2% acceptance rate)
<a href="https://arxiv.org/pdf/1904.04357.pdf" target="_blank">[pdf]</a>
<a href="./docs/cvpr19_videoqa.pdf" target="_blank">[poster]</a>
<a href="https://github.com/fanchenyou/HME-VideoQA" target="_blank">[code]</a> 
</li>

<li></font> <b>Chenyou Fan</b>, Heng Huang. "Multi-Horizon Time Series Forecasting with Temporal Attention Learning." 
SIGKDD Conference on Knowledge Discovery and Data Mining 2019 (KDD'19, 20% acceptance rate)
<a href="./docs/kdd19.pdf" target="_blank">[pdf]</a>
</li>


<!-- 
<li>Tianyi Lin, <b>Chenyou Fan</b>, Mengdi Wang, Michael I. Jordan. "Improved Oracle Complexity for Stochastic Compositional Variance Reduced Gradient.
<a href="https://arxiv.org/abs/1806.00458" target="_blank">[link]</a>
</li>
 -->
 
<li><b>Chenyou Fan</b>, Zehua Zhang, David J. Crandall. "DeepDiary: Lifelogging Image Captioning and Summarization." 2018. Journal of Visual Communication and Image Representation (Impact Factor: 2.591).
<a href="https://www.sciencedirect.com/science/article/pii/S1047320318301032" target="_blank">[link]</a>
</li>


<li> Mingze Xu, <b>Chenyou Fan</b>, Yuchen Wang, Michael S. Ryoo, David J. Crandall. "Joint Person Segmentation and Identification in Synchronized First-and Third-person Videos.
European Conference on Computer Vision 2018 (ECCV'18).
<a href="http://vision.soic.indiana.edu/firstthird-eccv2018/" target="_blank">[project]</a>
</li>

<!-- 
<li> Tianyi Lin, <b>Chenyou Fan</b>, Mengdi Wang. "Improved Incremental First-Order Oracle Complexity of Variance Reduced Methods for Nonsmooth Convex Stochastic Composition Optimization.
<a href="https://arxiv.org/pdf/1802.02339.pdf" target="_blank">[pdf]</a>
</li>
 -->

<li> Mingze Xu, <b>Chenyou Fan</b>, John Paden, Geoffrey Fox, and David J. Crandall. "Multi-Task Spatiotemporal Neural Networks for Structured Surface Reconstruction."
IEEE Winter Conference on Applications of Computer Vision 2018 (WACVâ€™18).
<a href="https://arxiv.org/pdf/1801.03986.pdf" target="_blank">[pdf]</a>
</li>

<!-- 
<li> <b>Chenyou Fan</b>, Jangwon Lee and Michael S. Ryoo. "Forecasting Hand and Object Locations inFuture Frames."
<a href="https://arxiv.org/abs/1705.07328" target="_blank">[ArXiv]</a>
</li>
 -->

<li> <b>Chenyou Fan</b>, Jangwon Lee, Mingze Xu, K.K. Singh, Y.J. Lee, David J. Crandall, Michael S. Ryoo, "Identifying first-person camera wearers in third-person videos", 
IEEE Conference on Computer Vision and Pattern Recognition 2017 (CVPR'17, 29.0% acceptance rate). <a href="https://arxiv.org/abs/1704.06340" target="_blank">[pdf]</a> 
<a href="./docs/cvpr2017_poster.pdf" target="_blank">[poster]</a> 
<a href="./docs/cvpr2017_video.mp4" target="_blank">[example video]</a> 
<a href="http://vision.soic.indiana.edu/identifying-1st-3rd/" target="_blank">[data & project page]</a> 
</li>

<li> AJ Piergiovanni, <b>Chenyou Fan</b>, and Michael S. Ryoo, "Learning Latent Sub-events in Activity Videos Using Temporal Attention Filters", 
the 31st AAAI Conference on Artificial Intelligence (AAAI), February 2017. 
 <a href="http://arxiv.org/abs/1605.08140" target="_blank">[pdf]</a> 
 <a href="https://github.com/piergiaj/latent-subevents" target="_blank">[source_code]</a>
</li>

</ul>
</span>

<hr style="width: 100%; height: 2px;">
<h2>Resources <span style="font-size: 18px;">
</span></h2> 
<ul>
<li> <b>Chenyou Fan</b>. "Survey of Convolutional Neural Network"
<a href="./docs/cnn_survey.pdf" target="_blank">pdf</a>
</li>
</ul>



<hr style="width: 100%; height: 2px;">
<h2>Workshops <span style="font-size: 18px;">
</span></h2> 
<ul>
<li> <b>Chenyou Fan</b>. "EgoVQA - An Egocentric Video Question Answering Benchmark Dataset".
International Workshop on Egocentric Perception, Interaction and Computing (EPIC@ICCV), Octorber 2019.
<a href="http://homes.sice.indiana.edu/fan6/docs/EgoVQA.pdf" target="_blank">[pdf]
<a href="https://github.com/fanchenyou/EgoVQA" target="_blank">[code & data]
<a href="https://drive.google.com/file/d/1pxezk8VnwVxajno_jQtVVnWOou12Aw7K/view?usp=sharing" target="_blank">[poster]</a>
</li>
<li> <b>Chenyou Fan</b>, Jangwon Lee and Michael S. Ryoo. "Forecasting Hand and Object Locations in Future Frames".
European Conference Workshop on Anticipating Human Behavior (AHB@ECCV), August 2018.
<a href="https://arxiv.org/abs/1705.07328" target="_blank">[pdf]</a>
</li>
<li> <b>Chenyou Fan</b> and David J. Crandall, "Deepdiary: Automatically Captioning Lifelogging Image Streams". 
European Conference Workshop on Egocentric Perception, Interaction, and Computing (EPIC@ECCV), October 2016.
<a href="http://vision.soic.indiana.edu/projects/deepdiary-automatically-captioning-lifelogging-image-streams/" target="_blank">[pdf and source_code]</a>  
<a href="./docs/ECCVW-poster.pdf" target="_blank">[poster]</a> 
</li>

</ul>


<hr style="width: 100%; height: 2px;">
<h2>Datasets</h2>
<ul>
<li>
<a href="http://vision.soic.indiana.edu/identifying-1st-3rd/" target="_blank">IU Multi-view egocentric video dataset</a>: 
A dataset of egocentric videos with two synchronized first-person cameras and a third-person camera<br>
</li>
</ul>

<hr style="width: 100%; height: 2px;">
<h2>Projects of Personal Interest</h2>
<ul>
<li>
Transformer models for NLP  <a href="https://github.com/fanchenyou/transformer-study" target="_blank">src</a><br>
</li>
<li>
RL  <a href="https://github.com/fanchenyou/RL-study" target="_blank">src</a><br>
</li>
</ul>


<hr style="width: 100%; height: 2px;">
<h2>Teaching</h2>
<ul>
<li>B551: Elements of Artificial Intelligence</li>
<li>B555: Algorithm Design and Analysis</li>
</ul>

<hr style="width: 100%; height: 2px;">
<h2>Vision Family</h2>
<img src="./pics/2017-11-03-family.jpg" alt="Happy time" style="width:400px;height:300px;">
<p>From left to right, AJ, Michael, David and Me. 2017-11-03 in a pub at IUB.</p>

		
<!-- <hr style="width: 100%; height: 2px;"> -->

<p align="right"><span style="font-size: 13px;">Updated 01/17/2020</span></p>

</mselli@umail.iu.edu></td></tr>
</tbody></table>






</body></html>
