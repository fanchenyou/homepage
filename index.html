<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!-- 
<script type="text/javascript" src="hits.php"></script>
 -->


	<title>Chenyou Fan</title>
	<style type="text/css">
	a {
		text-decoration:none;
	}
	a:link {
		color: #045FB4;
	}
	a:visited {
		color: #045FB4;
	}
	body {
		font-family:Arial;
		font-size: 15px;
	}
	li {
		padding: 5px;
	}
	</style>
</head>

<body bgcolor="white">


<table style="width: 1024px;" border="0" cellpadding="15" cellspacing="0"> 

<tbody><tr><td>


<table border="0" cellpadding="3" align="top">
	<tbody><tr>
		<td>
			<img src="pics/chenyou.jpg">
		</td>
		<td>
			<span style="font-size: 20px;"><b>Chenyou Fan</b></span><br>
			<span style="font-size: 17px;"><b>Ph.D.</b><br>
			<br>
			
<!-- 
			<span style="font-size: 16px;">Department of Computer Science and Informatics<br>
			<span style="font-size: 16px;">School of Informatics and Computing<br>
 -->
<!-- 
			<span style="font-size: 16px;">Indiana University Bloomington<br>
 -->


<br>

			<span style="font-size: 16px;"><b>Contact</b><br>
<!-- 			<a href="mailto:fan6@iu.edu">fan6-at-iu.edu</a> -->
			fanchenyou-at-gmail.com
		</span></span></span></span></span></span></span></td>
	</tr>
</tbody></table><br>

<!-- I am now a computer vision engineer at AI&BD team of JD.com USA. <br> -->
I obtained my Ph.D. degree of Computer Science from School of Informatics and Computing, <a href="http://www.iub.edu/" target="_blank">Indiana University</a>. <br>
<!-- My research interests include Computer Vision, Machine Learning, Natural Language Processing and Federated Learning.  <br> -->
<!-- My research topics include predicting robotics motion, recognizing first-person videos, and captioning first-person images with deep learning methods. <br> -->
My research topics include first-person videos, image captioning, video question answering, federated learning and time series analysis.
<br><br>


<hr style="width: 100%; height: 2px;">
<!-- <h3>Curriculum Vitae</h2> <a href="./docs/cv_2019.pdf" target="_blank">pdf</a></h2> -->
<h3>Google Scholar <a href="https://scholar.google.com/citations?user=FRu9MHcAAAAJ&hl=en" target="_blank">here</a></h2>


<hr style="width: 100%; height: 2px;">
<h2>Research<span style="font-size: 18px;">
</span></h2> 

I work in computer vision, machine learning and natural language understanding, where the areas in AI concerned with automatically perceiving the world from human perspectives.
More generally, I am interested and actively involved in solving problems by modeling and learning from large amounts of unstructured data such as images and texts, with a large number of agents and distributed devices.



<hr style="width: 100%; height: 2px;">
<h2>Publications <span style="font-size: 18px;">
</span></h2> 

<!-- <span style="font-size: 13px; font-family: lucida grande, verdana, sans-serif;"> -->
<!-- <h3>List of selected recent publications</h3> -->

<ul>

<li></font> <b>Chenyou Fan</b>, Jianwei Huang. "Federated Few-Shot Learning with Adversarial
Learning." 
19th International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks (WiOpt '21)
<!-- <a href="https://arxiv.org/abs/2006.07458" target="_blank">[pdf]</a> -->
<a href="./docs/fedfsl.pdf" target="_blank">[pdf]</a>
</li>


<li></font> <b>Chenyou Fan</b>, Junjie Hu, Jianwei Huang. "Few-Shot Multi-Agent Perception." 
29th ACM International Conference on Multimedia 2021 (ACM MM'21, 27.9% acceptance rate)
<!-- <a href="https://arxiv.org/abs/2006.07458" target="_blank">[pdf]</a> -->
<a href="./docs/fs_map_1.pdf" target="_blank">[pdf]</a>
<a href="https://github.com/fanchenyou/fs-map-project" target="_blank">[code]</a>
</li>

<li></font> Tianyi Lin, <b>Chenyou Fan</b> (co-first), Nhat Ho, Marco Cuturi, Michael I. Jordan. "Projection Robust Wasserstein Distance and Riemannian Optimization." 
Conference on Neural Information Processing Systems (NeurIPS'20, spotlight, 20% acceptance rate, 3% spotlight rate)
<a href="https://arxiv.org/abs/2006.07458" target="_blank">[pdf]</a>
<a href="https://github.com/fanchenyou/PRW" target="_blank">[code]</a>
</li>

<li></font> Tianyi Lin, <b>Chenyou Fan</b>, Mengdi Wang, M.I.Jordan. "Improved Sample Complexity for Stochastic Compositional Variance Reduced Gradient." 
American Control Conference 2020 (ACC'20)
<a href="https://arxiv.org/abs/1806.00458" target="_blank">[pdf]</a>
</li>

<li></font> <b>Chenyou Fan</b>, Heng Huang. "Heterogeneous Memory Enhanced Multimodal Attention Model for Video Question Answering." 
IEEE Conference on Computer Vision and Pattern Recognition 2019 (CVPR'19, 25.2% acceptance rate)
<a href="https://arxiv.org/pdf/1904.04357.pdf" target="_blank">[pdf]</a>
<a href="https://github.com/fanchenyou/HME-VideoQA" target="_blank">[code]</a> 
</li>

<li></font> <b>Chenyou Fan</b>, Heng Huang. "Multi-Horizon Time Series Forecasting with Temporal Attention Learning." 
SIGKDD Conference on Knowledge Discovery and Data Mining 2019 (KDD'19, 20% acceptance rate)
</li>

 
<li><b>Chenyou Fan</b>, Zehua Zhang, David J. Crandall. "DeepDiary: Lifelogging Image Captioning and Summarization." 2018. Journal of Visual Communication and Image Representation.
<a href="https://www.sciencedirect.com/science/article/pii/S1047320318301032" target="_blank">[link]</a>
</li>


<li> Mingze Xu, <b>Chenyou Fan</b>, Yuchen Wang, Michael S. Ryoo, David J. Crandall. "Joint Person Segmentation and Identification in Synchronized First-and Third-person Videos."
European Conference on Computer Vision 2018 (ECCV'18).
<a href="http://vision.soic.indiana.edu/firstthird-eccv2018/" target="_blank">[project]</a>
</li>


<li> Mingze Xu, <b>Chenyou Fan</b>, John Paden, Geoffrey Fox, and David J. Crandall. "Multi-Task Spatiotemporal Neural Networks for Structured Surface Reconstruction."
IEEE Winter Conference on Applications of Computer Vision 2018 (WACV’18).
<a href="https://arxiv.org/pdf/1801.03986.pdf" target="_blank">[pdf]</a>
</li>


<li> <b>Chenyou Fan</b>, Jangwon Lee, Mingze Xu, K.K. Singh, Y.J. Lee, David J. Crandall, Michael S. Ryoo, "Identifying first-person camera wearers in third-person videos", 
IEEE Conference on Computer Vision and Pattern Recognition 2017 (CVPR'17, 29.0% acceptance rate). <a href="https://arxiv.org/abs/1704.06340" target="_blank">[pdf]</a> 
<a href="http://vision.soic.indiana.edu/identifying-1st-3rd/" target="_blank">[data & project page]</a> 
</li>

<li> AJ Piergiovanni, <b>Chenyou Fan</b>, and Michael S. Ryoo, "Learning Latent Sub-events in Activity Videos Using Temporal Attention Filters", 
the 31st AAAI Conference on Artificial Intelligence (AAAI), February 2017. 
 <a href="http://arxiv.org/abs/1605.08140" target="_blank">[pdf]</a> 
 <a href="https://github.com/piergiaj/latent-subevents" target="_blank">[source_code]</a>
</li>

</ul>
</span>

<hr style="width: 100%; height: 2px;">
<h2>Resources <span style="font-size: 18px;">
</span></h2> 
<ul>
<li> <b>Chenyou Fan</b>. "Survey of Convolutional Neural Network"
<a href="./docs/cnn_survey.pdf" target="_blank">pdf</a>
</li>
</ul>



<hr style="width: 100%; height: 2px;">
<h2>More research work<span style="font-size: 18px;">
</span></h2> 
<ul>
<li></font>Hengyang Lu, <b>Chenyou Fan</b>. "Few-shot COVID-19 Rumor Detection for Online Social Media."
CCF Conference on Artificial Intelligence (CCFAI'21)
</li>
<li></font> <b>Chenyou Fan</b>, Ping Liu. "Federated Generative Adversarial Learning." 
Chinese Conference on Pattern Recognition and Computer Vision (PRCV'20)
<a href="https://arxiv.org/abs/2005.03793" target="_blank">[pdf]</a>
</li>
<li> <b>Chenyou Fan</b>. "EgoVQA - An Egocentric Video Question Answering Benchmark Dataset".
International Workshop on Egocentric Perception, Interaction and Computing (EPIC@ICCV), Octorber 2019.
<a href="http://openaccess.thecvf.com/content_ICCVW_2019/html/EPIC/Fan_EgoVQA_-_An_Egocentric_Video_Question_Answering_Benchmark_Dataset_ICCVW_2019_paper.html" target="_blank">[pdf]
<a href="https://github.com/fanchenyou/EgoVQA" target="_blank">[code & data]
<a href="https://drive.google.com/file/d/1pxezk8VnwVxajno_jQtVVnWOou12Aw7K/view?usp=sharing" target="_blank">[poster]</a>
</li>
<li> <b>Chenyou Fan</b>, Jangwon Lee and Michael S. Ryoo. "Forecasting Hand and Object Locations in Future Frames".
European Conference Workshop on Anticipating Human Behavior (AHB@ECCV), August 2018.
<a href="https://arxiv.org/abs/1705.07328" target="_blank">[pdf]</a>
</li>
<li> <b>Chenyou Fan</b> and David J. Crandall, "Deepdiary: Automatically Captioning Lifelogging Image Streams". 
European Conference Workshop on Egocentric Perception, Interaction, and Computing (EPIC@ECCV), October 2016.
<a href="http://vision.soic.indiana.edu/projects/deepdiary-automatically-captioning-lifelogging-image-streams/" target="_blank">[pdf and source_code]</a>  
</li>

</ul>


<hr style="width: 100%; height: 2px;">
<h2>Datasets</h2>
<ul>
<li>
<a href="http://vision.soic.indiana.edu/identifying-1st-3rd/" target="_blank">IU Multi-view egocentric video dataset</a>: 
A dataset of egocentric videos with two synchronized first-person cameras and a third-person camera<br>
</li>
</ul>

<hr style="width: 100%; height: 2px;">
<h2>Patent</h2>
<ul>
<li>
利用动态时间上下文学习进行多界限时间序列预测的系统和方法. [CN201910803743.5] <!--<a href="http://gb.oversea.cnki.net/KCMS/detail/detail.aspx?filename=CN110866628A&dbcode=SCPD" target="_blank">[CNKI Link]</a> -->
<br>
</li>
<li>
System and method for multi-horizon time series forecasting with dynamic temporal context learning. [US20200074274A1]
<br>
</li>

</ul>


<hr style="width: 100%; height: 2px;">
<h2>Teaching</h2>
<ul>
<li>Elements of Artificial Intelligence</li>
<li>Algorithm Design and Analysis</li>
</ul>


<p align="right"><span style="font-size: 13px;">Updated 04/30/2021</span></p>

</tbody></table>






</body></html>
